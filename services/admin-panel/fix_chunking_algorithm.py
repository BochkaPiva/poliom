#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —á–∞–Ω–∫–∏–Ω–≥–∞
"""

import sys
import os
from pathlib import Path
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ services
services_path = Path(__file__).parent.parent
sys.path.append(str(services_path))

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv('.env.local')

from shared.models.database import SessionLocal
from shared.models.document import DocumentChunk, Document
from shared.utils.embeddings import EmbeddingService

def improved_split_into_chunks(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
    """
    if not text or not text.strip():
        return []
    
    text = text.strip()
    
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –∫–∞–∫ –æ–¥–∏–Ω —á–∞–Ω–∫
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
        end = min(start + chunk_size, len(text))
        
        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫, –∏—â–µ–º —Ö–æ—Ä–æ—à–µ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑—Ä—ã–≤–∞
        if end < len(text):
            # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é –≥—Ä–∞–Ω–∏—Ü—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 200 —Å–∏–º–≤–æ–ª–∞—Ö —á–∞–Ω–∫–∞
            search_start = max(start, end - 200)
            
            # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
            best_break = -1
            
            # 1. –¢–æ—á–∫–∞ —Å –ø—Ä–æ–±–µ–ª–æ–º
            for i in range(end - 1, search_start - 1, -1):
                if i < len(text) - 1 and text[i] == '.' and text[i + 1] == ' ':
                    best_break = i + 1
                    break
            
            # 2. –í–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫ —Å –ø—Ä–æ–±–µ–ª–æ–º
            if best_break == -1:
                for i in range(end - 1, search_start - 1, -1):
                    if i < len(text) - 1 and text[i] in '!?' and text[i + 1] == ' ':
                        best_break = i + 1
                        break
            
            # 3. –î–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
            if best_break == -1:
                double_newline = text.rfind('\n\n', search_start, end)
                if double_newline != -1:
                    best_break = double_newline + 2
            
            # 4. –û–¥–∏–Ω–∞—Ä–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
            if best_break == -1:
                newline = text.rfind('\n', search_start, end)
                if newline != -1:
                    best_break = newline + 1
            
            # 5. –ü—Ä–æ–±–µ–ª (–ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)
            if best_break == -1:
                space = text.rfind(' ', search_start, end)
                if space != -1:
                    best_break = space + 1
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–µ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑—Ä—ã–≤–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if best_break != -1:
                end = best_break
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞–Ω–∫
        chunk = text[start:end].strip()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π –∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π
        if chunk and len(chunk) > 10:  # –ú–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤
            chunks.append(chunk)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–∞—á–∞–ª–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —á–∞–Ω–∫–∞
        if end >= len(text):
            break
        
        # –°–ª–µ–¥—É—é—â–∏–π —á–∞–Ω–∫ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —É—á–µ—Ç–æ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
        # –ù–û –Ω–µ —Ä–∞–Ω—å—à–µ —á–µ–º —á–µ—Ä–µ–∑ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥
        min_step = max(50, chunk_size // 4)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥ - 50 —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ 1/4 —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–∞
        next_start = max(start + min_step, end - overlap)
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –º—ã –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º—Å—è –≤–ø–µ—Ä–µ–¥
        if next_start <= start:
            next_start = start + min_step
        
        start = next_start
    
    return chunks

def test_improved_chunking():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —á–∞–Ω–∫–∏–Ω–≥–∞"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ê–õ–ì–û–†–ò–¢–ú–ê –ß–ê–ù–ö–ò–ù–ì–ê\n")
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    test_text = """
    –≠—Ç–æ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –û–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ –æ–ø–ª–∞—Ç—ã —Ç—Ä—É–¥–∞.
    
    –í—Ç–æ—Ä–æ–π –∞–±–∑–∞—Ü —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã. –ó–¥–µ—Å—å –æ–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞—Å—á–µ—Ç–∞.
    
    –¢—Ä–µ—Ç–∏–π —Ä–∞–∑–¥–µ–ª –ø–æ—Å–≤—è—â–µ–Ω –ø—Ä–µ–º–∏–∞–ª—å–Ω—ã–º –≤—ã–ø–ª–∞—Ç–∞–º. –í –Ω–µ–º —É–∫–∞–∑–∞–Ω—ã —É—Å–ª–æ–≤–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–º–∏–π –∏ –Ω–∞–¥–±–∞–≤–æ–∫.
    
    –ß–µ—Ç–≤–µ—Ä—Ç–∞—è —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Ç–ø—É—Å–∫–∞—Ö. –û–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –ø–æ—Ä—è–¥–æ–∫ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏ –æ–ø–ª–∞—Ç—ã –æ—Ç–ø—É—Å–∫–æ–≤.
    
    –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –≤–∫–ª—é—á–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è. –ó–¥–µ—Å—å —É–∫–∞–∑–∞–Ω—ã –æ—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏ –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.
    """ * 5  # –ü–æ–≤—Ç–æ—Ä—è–µ–º 5 —Ä–∞–∑ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    
    print(f"üìÑ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(test_text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    print("\nüî¥ –°–¢–ê–†–´–ô –∞–ª–≥–æ—Ä–∏—Ç–º:")
    old_chunks = old_split_into_chunks(test_text, chunk_size=300, overlap=50)
    print(f"   –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(old_chunks)}")
    for i, chunk in enumerate(old_chunks[:3]):
        print(f"   –ß–∞–Ω–∫ {i+1}: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤ - '{chunk[:50]}...'")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
    print("\nüü¢ –ù–û–í–´–ô –∞–ª–≥–æ—Ä–∏—Ç–º:")
    new_chunks = improved_split_into_chunks(test_text, chunk_size=300, overlap=50)
    print(f"   –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(new_chunks)}")
    for i, chunk in enumerate(new_chunks[:3]):
        print(f"   –ß–∞–Ω–∫ {i+1}: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤ - '{chunk[:50]}...'")

def old_split_into_chunks(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:
    """–°—Ç–∞—Ä—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    if not text or not text.strip():
        return []
    
    chunks = []
    text = text.strip()
    
    if len(text) <= chunk_size:
        return [text]
    
    start = 0
    while start < len(text):
        end = start + chunk_size
        
        if end < len(text):
            for separator in ['. ', '\n', ' ']:
                sep_pos = text.rfind(separator, start, end)
                if sep_pos != -1:
                    end = sep_pos + len(separator)
                    break
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        start = max(start + 1, end - overlap)  # –≠–¢–û –ü–†–û–ë–õ–ï–ú–ê!
    
    return chunks

def recreate_chunks_with_improved_algorithm(document_id: int = 1):
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º"""
    print(f"\nüîÑ –ü–ï–†–ï–°–û–ó–î–ê–ù–ò–ï –ß–ê–ù–ö–û–í –° –£–õ–£–ß–®–ï–ù–ù–´–ú –ê–õ–ì–û–†–ò–¢–ú–û–ú")
    
    db = SessionLocal()
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        document = db.query(Document).filter(Document.id == document_id).first()
        if not document:
            print(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç {document_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        print(f"\nüìÑ –î–æ–∫—É–º–µ–Ω—Ç: {document.original_filename}")
        print(f"üìÅ –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {document.file_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(document.file_path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {document.file_path}")
            return False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        from shared.utils.document_processor import DocumentProcessor
        processor = DocumentProcessor()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
        print("üìñ –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞...")
        try:
            text_content = processor.extract_text(document.file_path)
            if not text_content or not text_content.strip():
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return False
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ content –¥–æ–∫—É–º–µ–Ω—Ç–∞
        document.content = text_content
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏
        old_chunks = db.query(DocumentChunk).filter(DocumentChunk.document_id == document_id).all()
        print(f"üóëÔ∏è –ù–∞–π–¥–µ–Ω–æ {len(old_chunks)} —Å—Ç–∞—Ä—ã—Ö —á–∞–Ω–∫–æ–≤")
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏
        db.query(DocumentChunk).filter(DocumentChunk.document_id == document_id).delete()
        db.commit()
        print("‚úÖ –°—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏ —É–¥–∞–ª–µ–Ω—ã")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º
        print("‚úÇÔ∏è –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏...")
        new_chunks = improved_split_into_chunks(text_content, chunk_size=1000, overlap=200)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(new_chunks)} –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        from shared.utils.embeddings import EmbeddingService
        embedding_service = EmbeddingService()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        for i, chunk_text in enumerate(new_chunks):
            print(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫ {i+1}/{len(new_chunks)}...", end='\r')
            
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —á–∞–Ω–∫–∞
            embedding = embedding_service.create_embedding(chunk_text)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —á–∞–Ω–∫–∞
            chunk = DocumentChunk(
                document_id=document_id,
                chunk_index=i,
                content=chunk_text,
                content_length=len(chunk_text),
                embedding=embedding,
                created_at=datetime.utcnow()
            )
            
            db.add(chunk)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–µ 50 —á–∞–Ω–∫–æ–≤
            if (i + 1) % 50 == 0:
                db.commit()
                print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {i+1} —á–∞–Ω–∫–æ–≤...")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
        document.chunks_count = len(new_chunks)
        document.updated_at = datetime.utcnow()
        document.processing_status = "completed"
        
        db.commit()
        print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(new_chunks)} —á–∞–Ω–∫–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤
        print("\nüìä –ê–ù–ê–õ–ò–ó –ù–û–í–´–• –ß–ê–ù–ö–û–í:")
        chunk_sizes = [len(chunk) for chunk in new_chunks]
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {min(chunk_sizes)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {max(chunk_sizes)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {sum(chunk_sizes) / len(chunk_sizes):.1f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ú–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {sorted(chunk_sizes)[len(chunk_sizes)//2]} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        db.rollback()
        return False
    finally:
        db.close()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–ê –ß–ê–ù–ö–ò–ù–ì–ê\n")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º
    test_improved_chunking()
    
    # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    print("\n" + "="*60)
    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ë—É–¥—É—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω—ã –≤—Å–µ —á–∞–Ω–∫–∏ —Å –Ω–æ–≤—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º!")
    
    response = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ").strip().lower()
    if response != 'y':
        print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
        return
    
    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏
    success = recreate_chunks_with_improved_algorithm()
    
    if success:
        print("\n" + "="*60)
        print("üéâ –ê–õ–ì–û–†–ò–¢–ú –ß–ê–ù–ö–ò–ù–ì–ê –ò–°–ü–†–ê–í–õ–ï–ù!")
        print("‚úÖ –¢–µ–ø–µ—Ä—å —á–∞–Ω–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏")
        print("‚úÖ –ü–æ–∏—Å–∫ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–º–Ω–æ–≥–æ –ª—É—á—à–µ")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å —á–∞–Ω–∫–∏–Ω–≥")

if __name__ == "__main__":
    main() 