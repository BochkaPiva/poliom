#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —á–∞–Ω–∫–æ–≤
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ shared –º–æ–¥—É–ª—è–º
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "shared"))

from utils.embeddings import SimpleEmbeddings
from utils.document_processor import DocumentProcessor
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_embedding_quality():
    """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    
    embeddings = SimpleEmbeddings()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    test_texts = [
        "–ó–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –¥–≤–∞ —Ä–∞–∑–∞ –≤ –º–µ—Å—è—Ü",
        "–ó–∞—Ä–ø–ª–∞—Ç–∞ –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç—Å—è 12 –∏ 27 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞",
        "–û—Ç–ø—É—Å–∫–Ω—ã–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—é—Ç—Å—è –∑–∞ —Ç—Ä–∏ –¥–Ω—è –¥–æ –æ—Ç–ø—É—Å–∫–∞",
        "–†–∞–±–æ—á–∏–π –¥–µ–Ω—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –≤ 9:00 —É—Ç—Ä–∞",
        "–û–±–µ–¥–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Ä—ã–≤ –¥–ª–∏—Ç—Å—è –æ–¥–∏–Ω —á–∞—Å"
    ]
    
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    embeddings_list = []
    for text in test_texts:
        emb = embeddings.create_embedding(text)
        embeddings_list.append(emb)
        print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω –¥–ª—è: '{text[:50]}...' (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(emb)})")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
    print("\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏:")
    similarity_salary = embeddings.calculate_similarity(embeddings_list[0], embeddings_list[1])
    similarity_different = embeddings.calculate_similarity(embeddings_list[0], embeddings_list[3])
    
    print(f"–°—Ö–æ–∂–µ—Å—Ç—å –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: {similarity_salary:.3f}")
    print(f"–°—Ö–æ–∂–µ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö —Ç–µ–º: {similarity_different:.3f}")
    
    return embeddings.get_model_info()

def test_chunking_quality():
    """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\nüìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è...")
    
    processor = DocumentProcessor()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç (–∏–º–∏—Ç–∞—Ü–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
    test_text = """
    –ü–û–õ–û–ñ–ï–ù–ò–ï –û –ó–ê–†–ê–ë–û–¢–ù–û–ô –ü–õ–ê–¢–ï
    
    1. –û–ë–©–ò–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø
    –ù–∞—Å—Ç–æ—è—â–µ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –Ω–∞—á–∏—Å–ª–µ–Ω–∏—è –∏ –≤—ã–ø–ª–∞—Ç—ã –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –∫–æ–º–ø–∞–Ω–∏–∏.
    
    2. –°–†–û–ö–ò –í–´–ü–õ–ê–¢–´
    –ó–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –¥–≤–∞ —Ä–∞–∑–∞ –≤ –º–µ—Å—è—Ü:
    - –ê–≤–∞–Ω—Å –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è 12 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ 40% –æ—Ç –æ–∫–ª–∞–¥–∞
    - –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è 27 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞
    
    –í —Å–ª—É—á–∞–µ –µ—Å–ª–∏ –¥–µ–Ω—å –≤—ã–ø–ª–∞—Ç—ã –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –∏–ª–∏ –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–π –¥–µ–Ω—å, –≤—ã–ø–ª–∞—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å.
    
    3. –ü–û–†–Ø–î–û–ö –ù–ê–ß–ò–°–õ–ï–ù–ò–Ø
    –ó–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞ –Ω–∞—á–∏—Å–ª—è–µ—Ç—Å—è –∏—Å—Ö–æ–¥—è –∏–∑ –æ—Ç—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –æ–∫–ª–∞–¥–∞.
    –ü—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è:
    - –û–∫–ª–∞–¥ —Å–æ–≥–ª–∞—Å–Ω–æ —à—Ç–∞—Ç–Ω–æ–º—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
    - –ü—Ä–µ–º–∏–∏ –∏ –¥–æ–ø–ª–∞—Ç—ã
    - –†–∞–π–æ–Ω–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
    - –£–¥–µ—Ä–∂–∞–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É
    
    4. –û–¢–ü–£–°–ö–ù–´–ï –í–´–ü–õ–ê–¢–´
    –û—Ç–ø—É—Å–∫–Ω—ã–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—é—Ç—Å—è –Ω–µ –ø–æ–∑–¥–Ω–µ–µ —á–µ–º –∑–∞ 3 –¥–Ω—è –¥–æ –Ω–∞—á–∞–ª–∞ –æ—Ç–ø—É—Å–∫–∞.
    –†–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –∏—Å—Ö–æ–¥—è –∏–∑ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞—Ä–∞–±–æ—Ç–∫–∞ –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤.
    
    5. –ë–û–õ–¨–ù–ò–ß–ù–´–ï –í–´–ü–õ–ê–¢–´
    –ü–æ—Å–æ–±–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.
    
    6. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –í–´–ü–õ–ê–¢–´
    –ö–æ–º–ø–∞–Ω–∏—è –º–æ–∂–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã–ø–ª–∞—Ç—ã –≤ –≤–∏–¥–µ –ø—Ä–µ–º–∏–π, –±–æ–Ω—É—Å–æ–≤ –∏ –¥—Ä—É–≥–∏—Ö –ø–æ–æ—â—Ä–µ–Ω–∏–π.
    –†–∞–∑–º–µ—Ä –∏ —É—Å–ª–æ–≤–∏—è —Ç–∞–∫–∏—Ö –≤—ã–ø–ª–∞—Ç –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∫–∞–∑–∞–º–∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.
    
    7. –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨
    –ó–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ä–æ–∫–æ–≤ –≤—ã–ø–ª–∞—Ç—ã –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –∫–æ–º–ø–∞–Ω–∏—è –Ω–µ—Å–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç—Ä—É–¥–æ–≤—ã–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.
    """ * 2  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1000 —Å–∏–º–≤–æ–ª–æ–≤)
    old_chunks = processor.split_into_chunks(test_text, chunk_size=1000, overlap=200)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1500 —Å–∏–º–≤–æ–ª–æ–≤)
    new_chunks = processor.split_into_chunks(test_text, chunk_size=1500, overlap=200)
    
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"–°—Ç–∞—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1000): {len(old_chunks)} —á–∞–Ω–∫–æ–≤")
    print(f"–ù–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1500): {len(new_chunks)} —á–∞–Ω–∫–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
    old_sizes = [len(chunk) for chunk in old_chunks]
    new_sizes = [len(chunk) for chunk in new_chunks]
    
    print(f"\nüìè –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ (—Å—Ç–∞—Ä—ã–µ):")
    print(f"   –ú–∏–Ω: {min(old_sizes)}, –ú–∞–∫—Å: {max(old_sizes)}, –°—Ä–µ–¥–Ω–∏–π: {sum(old_sizes)/len(old_sizes):.1f}")
    
    print(f"üìè –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ (–Ω–æ–≤—ã–µ):")
    print(f"   –ú–∏–Ω: {min(new_sizes)}, –ú–∞–∫—Å: {max(new_sizes)}, –°—Ä–µ–¥–Ω–∏–π: {sum(new_sizes)/len(new_sizes):.1f}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞:")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –∑–∞—Ä–ø–ª–∞—Ç–µ
    salary_context_old = sum(1 for chunk in old_chunks if '–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞' in chunk.lower() and '12' in chunk and '27' in chunk)
    salary_context_new = sum(1 for chunk in new_chunks if '–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞' in chunk.lower() and '12' in chunk and '27' in chunk)
    
    print(f"–ß–∞–Ω–∫–æ–≤ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –æ –∑–∞—Ä–ø–ª–∞—Ç–µ (—Å—Ç–∞—Ä—ã–µ): {salary_context_old}")
    print(f"–ß–∞–Ω–∫–æ–≤ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –æ –∑–∞—Ä–ø–ª–∞—Ç–µ (–Ω–æ–≤—ã–µ): {salary_context_new}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    complete_info_old = sum(1 for chunk in old_chunks if '–∞–≤–∞–Ω—Å' in chunk.lower() and '–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å' in chunk.lower())
    complete_info_new = sum(1 for chunk in new_chunks if '–∞–≤–∞–Ω—Å' in chunk.lower() and '–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å' in chunk.lower())
    
    print(f"–ß–∞–Ω–∫–æ–≤ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—ã–ø–ª–∞—Ç–∞—Ö (—Å—Ç–∞—Ä—ã–µ): {complete_info_old}")
    print(f"–ß–∞–Ω–∫–æ–≤ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—ã–ø–ª–∞—Ç–∞—Ö (–Ω–æ–≤—ã–µ): {complete_info_new}")
    
    return {
        'old_chunks_count': len(old_chunks),
        'new_chunks_count': len(new_chunks),
        'old_avg_size': sum(old_sizes)/len(old_sizes),
        'new_avg_size': sum(new_sizes)/len(new_sizes),
        'context_preservation_old': salary_context_old,
        'context_preservation_new': salary_context_new,
        'complete_info_old': complete_info_old,
        'complete_info_new': complete_info_new
    }

def analyze_token_efficiency():
    """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤"""
    print("\nüéØ –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤...")
    
    # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    # 1 —Ç–æ–∫–µ–Ω ‚âà 0.75 —Å–ª–æ–≤–∞ ‚âà 4-5 —Å–∏–º–≤–æ–ª–æ–≤
    
    old_chunk_size = 1000  # —Å–∏–º–≤–æ–ª–æ–≤
    new_chunk_size = 1500  # —Å–∏–º–≤–æ–ª–æ–≤
    
    old_tokens_per_chunk = old_chunk_size / 4.5  # –ø—Ä–∏–º–µ—Ä–Ω–æ
    new_tokens_per_chunk = new_chunk_size / 4.5
    
    old_chunks_for_context = 50  # —Å—Ç–∞—Ä—ã–π –ª–∏–º–∏—Ç
    new_chunks_for_context = 25  # –Ω–æ–≤—ã–π –ª–∏–º–∏—Ç
    
    old_total_tokens = old_tokens_per_chunk * old_chunks_for_context
    new_total_tokens = new_tokens_per_chunk * new_chunks_for_context
    
    print(f"üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤:")
    print(f"–°—Ç–∞—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤ –Ω–∞ —á–∞–Ω–∫: ~{old_tokens_per_chunk:.0f}")
    print(f"   –ß–∞–Ω–∫–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: {old_chunks_for_context}")
    print(f"   –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: ~{old_total_tokens:.0f} —Ç–æ–∫–µ–Ω–æ–≤")
    
    print(f"–ù–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤ –Ω–∞ —á–∞–Ω–∫: ~{new_tokens_per_chunk:.0f}")
    print(f"   –ß–∞–Ω–∫–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: {new_chunks_for_context}")
    print(f"   –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: ~{new_total_tokens:.0f} —Ç–æ–∫–µ–Ω–æ–≤")
    
    efficiency_improvement = (old_total_tokens - new_total_tokens) / old_total_tokens * 100
    
    print(f"\n‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {efficiency_improvement:.1f}%")
    print(f"   –≠–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤: ~{old_total_tokens - new_total_tokens:.0f} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"   –ë–æ–ª—å—à–µ –º–µ—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞: +{2500 - 1000} —Ç–æ–∫–µ–Ω–æ–≤")
    
    return {
        'old_total_tokens': old_total_tokens,
        'new_total_tokens': new_total_tokens,
        'efficiency_improvement': efficiency_improvement
    }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üîß –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• –ù–ê–°–¢–†–û–ï–ö")
    print("=" * 50)
    
    # –¢–µ—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embedding_info = test_embedding_quality()
    print(f"\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:")
    for key, value in embedding_info.items():
        print(f"   {key}: {value}")
    
    # –¢–µ—Å—Ç —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è
    chunking_results = test_chunking_quality()
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤
    token_analysis = analyze_token_efficiency()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
    print("=" * 50)
    
    print(f"\n‚úÖ –≠–ú–ë–ï–î–î–ò–ù–ì–ò:")
    print(f"   –ú–æ–¥–µ–ª—å: {embedding_info['model_name']}")
    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {embedding_info['embedding_dimension']}")
    print(f"   –Ø–∑—ã–∫: {embedding_info['language']}")
    print(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: {embedding_info['cost']}")
    
    print(f"\n‚úÖ –ß–ê–ù–ö–ò–†–û–í–ê–ù–ò–ï:")
    print(f"   –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤: {chunking_results['old_chunks_count']} ‚Üí {chunking_results['new_chunks_count']}")
    print(f"   –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: {chunking_results['old_avg_size']:.0f} ‚Üí {chunking_results['new_avg_size']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –£–ª—É—á—à–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {chunking_results['context_preservation_old']} ‚Üí {chunking_results['context_preservation_new']}")
    print(f"   –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ —á–∞–Ω–∫–∞—Ö: {chunking_results['complete_info_old']} ‚Üí {chunking_results['complete_info_new']}")
    
    print(f"\n‚úÖ –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ –¢–û–ö–ï–ù–û–í:")
    print(f"   –≠–∫–æ–Ω–æ–º–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {token_analysis['efficiency_improvement']:.1f}%")
    print(f"   –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ –æ—Ç–≤–µ—Ç–∞: 1000 ‚Üí 2500 —Ç–æ–∫–µ–Ω–æ–≤ (+150%)")
    
    print(f"\nüéØ –ü–†–ò–ú–ï–ù–Å–ù–ù–´–ï –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    print(f"   ‚úÖ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤: 1000 ‚Üí 1500 —Å–∏–º–≤–æ–ª–æ–≤ (+50%)")
    print(f"   ‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã GigaChat: 1000 ‚Üí 2500 (+150%)")
    print(f"   ‚úÖ –õ–∏–º–∏—Ç –ø–æ–∏—Å–∫–∞ —á–∞–Ω–∫–æ–≤: 50 ‚Üí 25 (-50%)")
    print(f"   ‚úÖ –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏: 0.3 ‚Üí 0.4 (+33%)")
    
    print(f"\nüöÄ –û–ñ–ò–î–ê–ï–ú–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
    print(f"   üìà –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ —Å—á–µ—Ç –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ —á–∞–Ω–∫–∞—Ö")
    print(f"   ‚ö° –ë—ã—Å—Ç—Ä–µ–µ –ø–æ–∏—Å–∫ –∑–∞ —Å—á–µ—Ç –º–µ–Ω—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —á–∞–Ω–∫–æ–≤")
    print(f"   üéØ –¢–æ—á–Ω–µ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ —Å—á–µ—Ç –ø–æ–≤—ã—à–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏")
    print(f"   üìù –ë–æ–ª–µ–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã –∑–∞ —Å—á–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"   üí∞ –≠–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    
    print(f"\nüîç –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ï–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    print(f"   üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ")
    print(f"   üîÑ –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   ‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é –ø–æ–∏—Å–∫–∞")
    print(f"   üìà –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–∏ —Ä–æ—Å—Ç–µ –Ω–∞–≥—Ä—É–∑–∫–∏")

if __name__ == "__main__":
    main() 