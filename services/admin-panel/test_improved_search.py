#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import logging
from datetime import datetime
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)

def test_search_settings():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ SQL"""
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê–°–¢–†–û–ï–ö –ü–û–ò–°–ö–ê")
    print("=" * 60)
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@localhost:5433/poliom')
    
    try:
        engine = create_engine(DATABASE_URL)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        db = SessionLocal()
        
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        result = db.execute(text("SELECT COUNT(*) FROM documents WHERE processing_status = 'completed'"))
        docs_count = result.scalar()
        print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {docs_count}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
        result = db.execute(text("SELECT COUNT(*) FROM document_chunks WHERE embedding IS NOT NULL"))
        chunks_count = result.scalar()
        print(f"üß© –ß–∞–Ω–∫–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {chunks_count}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤
        result = db.execute(text("SELECT AVG(content_length) FROM document_chunks WHERE content_length > 0"))
        avg_chunk_size = result.scalar()
        print(f"üìè –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {avg_chunk_size:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        try:
            result = db.execute(text("SELECT vector_dims(embedding) FROM document_chunks WHERE embedding IS NOT NULL LIMIT 1"))
            embedding_dim = result.scalar()
            print(f"üî¢ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embedding_dim}")
        except Exception as e:
            print(f"üî¢ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å ({str(e)[:50]})")
            embedding_dim = None
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏
        test_questions = [
            "–ö–æ–≥–¥–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –∑–∞—Ä–ø–ª–∞—Ç–∞?",
            "–†–∞–∑–º–µ—Ä –∞–≤–∞–Ω—Å–∞",
            "–ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã",
            "–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–ø—É—Å–∫?",
            "–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è"
        ]
        
        print(f"\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–ê:")
        print("-" * 40)
        
        for question in test_questions:
            print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
            words = question.lower().split()
            search_conditions = []
            params = {}
            
            for i, word in enumerate(words):
                if len(word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                    param_name = f'word_{i}'
                    search_conditions.append(f"dc.content ILIKE :{param_name}")
                    params[param_name] = f'%{word}%'
            
            if search_conditions:
                query = text(f"""
                    SELECT COUNT(*) as count
                    FROM document_chunks dc
                    JOIN documents d ON dc.document_id = d.id
                    WHERE d.processing_status = 'completed'
                      AND dc.content_length > 100
                      AND ({' OR '.join(search_conditions)})
                """)
                
                result = db.execute(query, params)
                found_count = result.scalar()
                print(f"   üìö –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤ (—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫): {found_count}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
                if found_count > 0:
                    query_sample = text(f"""
                        SELECT dc.content, dc.content_length
                        FROM document_chunks dc
                        JOIN documents d ON dc.document_id = d.id
                        WHERE d.processing_status = 'completed'
                          AND dc.content_length > 100
                          AND ({' OR '.join(search_conditions)})
                        LIMIT 3
                    """)
                    
                    result = db.execute(query_sample, params)
                    for i, row in enumerate(result, 1):
                        preview = row.content[:100].replace('\n', ' ')
                        print(f"   {i}. [{row.content_length} —Å–∏–º–≤.] {preview}...")
            else:
                print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –ß–ê–ù–ö–û–í:")
        print("-" * 40)
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        size_ranges = [
            (0, 500, "–ú–∞–ª–µ–Ω—å–∫–∏–µ"),
            (500, 1000, "–°—Ä–µ–¥–Ω–∏–µ"),
            (1000, 1500, "–ë–æ–ª—å—à–∏–µ"),
            (1500, 2000, "–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ"),
            (2000, 999999, "–û–≥—Ä–æ–º–Ω—ã–µ")
        ]
        
        for min_size, max_size, label in size_ranges:
            result = db.execute(text("""
                SELECT COUNT(*) 
                FROM document_chunks 
                WHERE content_length BETWEEN :min_size AND :max_size
                  AND embedding IS NOT NULL
            """), {'min_size': min_size, 'max_size': max_size})
            
            count = result.scalar()
            percentage = (count / chunks_count * 100) if chunks_count > 0 else 0
            print(f"   {label} ({min_size}-{max_size}): {count} ({percentage:.1f}%)")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("-" * 40)
        
        if avg_chunk_size < 800:
            print("‚ö†Ô∏è –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –º–∞–ª - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 1000-1500 —Å–∏–º–≤–æ–ª–æ–≤")
        elif avg_chunk_size > 2000:
            print("‚ö†Ô∏è –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –≤–µ–ª–∏–∫ - –º–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞")
        else:
            print("‚úÖ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –æ–ø—Ç–∏–º–∞–ª–µ–Ω")
        
        if chunks_count < 100:
            print("‚ö†Ô∏è –ú–∞–ª–æ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ - –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        else:
            print(f"‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {chunks_count}")
        
        if embedding_dim == 312:
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è rubert-tiny2 (312 –∏–∑–º–µ—Ä–µ–Ω–∏–π)")
        elif embedding_dim == 1024:
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–æ–ª–µ–µ –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å (1024 –∏–∑–º–µ—Ä–µ–Ω–∏—è)")
        else:
            print(f"‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ({embedding_dim} –∏–∑–º–µ—Ä–µ–Ω–∏–π)")
        
        db.close()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print(f"üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–∏—Å–∫–∞")
    print(f"‚è∞ –í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    test_search_settings()
    
    print("\n" + "=" * 60)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 60)

if __name__ == "__main__":
    main() 