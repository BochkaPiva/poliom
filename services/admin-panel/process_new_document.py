#!/usr/bin/env python3
"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º —á–∞–Ω–∫–∏–Ω–≥–∞
"""

import os
import sys
from pathlib import Path
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ services
services_path = Path(__file__).parent.parent
sys.path.append(str(services_path))

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv('.env.local')

from sqlalchemy.orm import sessionmaker
from shared.models.database import engine
from shared.models import Document, DocumentChunk
from shared.utils.document_processor import DocumentProcessor
from shared.utils.embeddings import EmbeddingService

# –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def process_document_with_improved_chunking(document_id: int):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º —á–∞–Ω–∫–∏–Ω–≥–∞"""
    print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ID: {document_id} —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º")
    
    db = SessionLocal()
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        document = db.query(Document).filter(Document.id == document_id).first()
        if not document:
            print(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç {document_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {document.original_filename}")
        print(f"üìÅ –ü—É—Ç—å: {document.file_path}")
        print(f"üìä –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: {document.processing_status}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        file_path = Path(document.file_path)
        if not file_path.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {document.file_path}")
            return False
        
        print(f"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {file_path.stat().st_size} –±–∞–π—Ç")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "processing"
        document.processing_status = "processing"
        document.updated_at = datetime.utcnow()
        db.commit()
        print("üìä –°—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ 'processing'")
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        old_chunks = db.query(DocumentChunk).filter(DocumentChunk.document_id == document_id).all()
        if old_chunks:
            print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º {len(old_chunks)} —Å—Ç–∞—Ä—ã—Ö —á–∞–Ω–∫–æ–≤...")
            for chunk in old_chunks:
                db.delete(chunk)
            db.commit()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        processor = DocumentProcessor()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        print("üìñ –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
        text_content = processor.extract_text(document.file_path)
        if not text_content or not text_content.strip():
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
        
        print(f"‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω: {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å –£–õ–£–ß–®–ï–ù–ù–´–ú –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º
        print("‚úÇÔ∏è –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ (—É–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º)...")
        chunks = processor.split_into_chunks(text_content, chunk_size=1000, overlap=200)
        if not chunks:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏")
        
        print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        chunk_sizes = [len(chunk) for chunk in chunks]
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤:")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {min(chunk_sizes)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {max(chunk_sizes)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {sum(chunk_sizes) / len(chunk_sizes):.1f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ú–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {sorted(chunk_sizes)[len(chunk_sizes)//2]} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤:")
        for i, chunk in enumerate(chunks[:3]):
            print(f"\n--- –ß–∞–Ω–∫ {i+1} ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤) ---")
            print(chunk[:300] + "..." if len(chunk) > 300 else chunk)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        print("\nüß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        embedding_service = EmbeddingService()
        
        # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        print("üíæ –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        created_chunks = []
        for i, chunk_text in enumerate(chunks):
            try:
                print(f"  üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫ {i+1}/{len(chunks)}...")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —á–∞–Ω–∫–∞
                embedding = embedding_service.get_embedding(chunk_text)
                
                # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                chunk = DocumentChunk(
                    document_id=document.id,
                    chunk_index=i,
                    content=chunk_text,
                    content_length=len(chunk_text),
                    embedding=embedding,
                    created_at=datetime.utcnow()
                )
                
                db.add(chunk)
                created_chunks.append(chunk)
                
                # –ö–æ–º–º–∏—Ç–∏–º –∫–∞–∂–¥—ã–µ 10 —á–∞–Ω–∫–æ–≤ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –ø–∞–º—è—Ç—å—é
                if (i + 1) % 10 == 0:
                    db.commit()
                    print(f"  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {i+1} —á–∞–Ω–∫–æ–≤...")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–∞ {i}: {str(e)}")
                continue
        
        if not created_chunks:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞")
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print("üíæ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤...")
        db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ "completed"
        document.processing_status = "completed"
        document.processed_at = datetime.utcnow()
        document.updated_at = datetime.utcnow()
        document.chunks_count = len(created_chunks)
        db.commit()
        
        print(f"\nüéâ –î–æ–∫—É–º–µ–Ω—Ç {document_id} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!")
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(created_chunks)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")
        print(f"üìä –°—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ 'completed'")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {str(e)}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ "failed"
        try:
            document = db.query(Document).filter(Document.id == document_id).first()
            if document:
                document.processing_status = "failed"
                document.error_message = str(e)
                document.updated_at = datetime.utcnow()
                db.commit()
                print("üìä –°—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ 'failed'")
        except Exception as db_error:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {str(db_error)}")
        
        return False
        
    finally:
        db.close()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º —á–∞–Ω–∫–∏–Ω–≥–∞\n")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å ID 2
    document_id = 2
    success = process_document_with_improved_chunking(document_id)
    
    if success:
        print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("üîç –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        db = SessionLocal()
        try:
            document = db.query(Document).filter(Document.id == document_id).first()
            if document:
                print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {document.original_filename}")
                print(f"üìä –°—Ç–∞—Ç—É—Å: {document.processing_status}")
                print(f"üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {document.chunks_count}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞–Ω–∫–∏ –≤ –±–∞–∑–µ
                chunks = db.query(DocumentChunk).filter(DocumentChunk.document_id == document_id).all()
                if chunks:
                    chunk_sizes = [chunk.content_length for chunk in chunks]
                    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
                    print(f"   –ß–∞–Ω–∫–æ–≤ –≤ –ë–î: {len(chunks)}")
                    print(f"   –ú–∏–Ω. —Ä–∞–∑–º–µ—Ä: {min(chunk_sizes)} —Å–∏–º–≤–æ–ª–æ–≤")
                    print(f"   –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {max(chunk_sizes)} —Å–∏–º–≤–æ–ª–æ–≤")
                    print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {sum(chunk_sizes) / len(chunk_sizes):.1f} —Å–∏–º–≤–æ–ª–æ–≤")
        finally:
            db.close()
    else:
        print("\n‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–æ–π!")
    
    return success

if __name__ == "__main__":
    main() 