#!/usr/bin/env python3
"""
–ë–ï–ó–û–ü–ê–°–ù–´–ô –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
–û–±—Ö–æ–¥–∏—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å PostgreSQL vector —Ç–∏–ø–∞–º–∏
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ services
services_path = Path(__file__).parent.parent
sys.path.append(str(services_path))

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv('.env.local')

from sqlalchemy.orm import sessionmaker
from sqlalchemy import text
from shared.models.database import engine
from shared.models import Document

# –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def analyze_chunk_sizes_safe():
    """–ë–ï–ó–û–ü–ê–°–ù–´–ô –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    print("üìä –ë–ï–ó–û–ü–ê–°–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –ß–ê–ù–ö–û–í")
    print("=" * 60)
    
    db = SessionLocal()
    try:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–µ—Ä–µ–∑ SQL
        print("üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ê–ù–ö–û–í:")
        
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
        total_chunks = db.execute(text("SELECT COUNT(*) FROM document_chunks")).fetchone()[0]
        
        if total_chunks == 0:
            print("‚ùå –ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        print(f"üì¶ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        stats = db.execute(text("""
            SELECT 
                MIN(content_length) as min_size,
                MAX(content_length) as max_size,
                ROUND(AVG(content_length)) as avg_size,
                SUM(content_length) as total_size
            FROM document_chunks
        """)).fetchone()
        
        if stats:
            print(f"üìè –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤:")
            print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {stats[0]} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {stats[1]} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   –°—Ä–µ–¥–Ω–∏–π: {stats[2]} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stats[3]:,} —Å–∏–º–≤–æ–ª–æ–≤")
        
        print()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        print("üìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –†–ê–ó–ú–ï–†–ê–ú:")
        
        size_ranges = [
            (0, 100, "–û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ (0-100)"),
            (101, 300, "–ú–∞–ª–µ–Ω—å–∫–∏–µ (101-300)"),
            (301, 600, "–°—Ä–µ–¥–Ω–∏–µ (301-600)"),
            (601, 1000, "–ë–æ–ª—å—à–∏–µ (601-1000)"),
            (1001, 1500, "–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ (1001-1500)"),
            (1501, 999999, "–û–≥—Ä–æ–º–Ω—ã–µ (>1500)")
        ]
        
        for min_size, max_size, label in size_ranges:
            if max_size == 999999:
                count = db.execute(text("""
                    SELECT COUNT(*) FROM document_chunks 
                    WHERE content_length >= :min_size
                """), {"min_size": min_size}).fetchone()[0]
            else:
                count = db.execute(text("""
                    SELECT COUNT(*) FROM document_chunks 
                    WHERE content_length BETWEEN :min_size AND :max_size
                """), {"min_size": min_size, "max_size": max_size}).fetchone()[0]
            
            percentage = (count / total_chunks * 100) if total_chunks > 0 else 0
            print(f"   {label}: {count} ({percentage:.1f}%)")
        
        print()
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
        print("üìÑ –ê–ù–ê–õ–ò–ó –ü–û –î–û–ö–£–ú–ï–ù–¢–ê–ú:")
        
        documents = db.query(Document).all()
        
        for doc in documents:
            print(f"\nüìÑ {doc.original_filename} (ID: {doc.id}):")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            doc_stats = db.execute(text("""
                SELECT 
                    COUNT(*) as chunk_count,
                    MIN(content_length) as min_size,
                    MAX(content_length) as max_size,
                    ROUND(AVG(content_length)) as avg_size
                FROM document_chunks 
                WHERE document_id = :doc_id
            """), {"doc_id": doc.id}).fetchone()
            
            if doc_stats and doc_stats[0] > 0:
                print(f"   üì¶ –ß–∞–Ω–∫–æ–≤: {doc_stats[0]}")
                print(f"   üìè –†–∞–∑–º–µ—Ä—ã: –º–∏–Ω={doc_stats[1]}, –º–∞–∫—Å={doc_stats[2]}, —Å—Ä–µ–¥–Ω–∏–π={doc_stats[3]}")
                
                # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —á–∞–Ω–∫–∏
                small_chunks = db.execute(text("""
                    SELECT COUNT(*) FROM document_chunks 
                    WHERE document_id = :doc_id AND content_length < 200
                """), {"doc_id": doc.id}).fetchone()[0]
                
                large_chunks = db.execute(text("""
                    SELECT COUNT(*) FROM document_chunks 
                    WHERE document_id = :doc_id AND content_length > 1500
                """), {"doc_id": doc.id}).fetchone()[0]
                
                if small_chunks > 0:
                    print(f"   ‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏—Ö —á–∞–Ω–∫–æ–≤ (<200): {small_chunks}")
                
                if large_chunks > 0:
                    print(f"   ‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö —á–∞–Ω–∫–æ–≤ (>1500): {large_chunks}")
                
                # –ö–∞—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
                quality_score = 100
                if small_chunks > doc_stats[0] * 0.1:  # –ë–æ–ª–µ–µ 10% –º–∞–ª–µ–Ω—å–∫–∏—Ö
                    quality_score -= 20
                if large_chunks > doc_stats[0] * 0.05:  # –ë–æ–ª–µ–µ 5% –±–æ–ª—å—à–∏—Ö
                    quality_score -= 15
                if doc_stats[3] < 500 or doc_stats[3] > 1200:  # –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –Ω–µ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                    quality_score -= 10
                
                print(f"   üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {quality_score}%")
                
            else:
                print(f"   üì¶ –ß–∞–Ω–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        print()
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        if stats:
            avg_size = stats[2]
            min_size = stats[0]
            max_size = stats[1]
            
            recommendations = []
            
            if avg_size < 500:
                recommendations.append("üìà –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å target_chunk_size")
            elif avg_size > 1200:
                recommendations.append("üìâ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å target_chunk_size")
            else:
                recommendations.append("‚úÖ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ")
            
            if min_size < 50:
                recommendations.append("‚ö†Ô∏è –ï—Å—Ç—å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–∑–±–∏–µ–Ω–∏—è")
            
            if max_size > 2000:
                recommendations.append("‚ö†Ô∏è –ï—Å—Ç—å –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ max_chunk_size")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            small_count = db.execute(text("""
                SELECT COUNT(*) FROM document_chunks WHERE content_length < 200
            """)).fetchone()[0]
            
            large_count = db.execute(text("""
                SELECT COUNT(*) FROM document_chunks WHERE content_length > 1500
            """)).fetchone()[0]
            
            small_percentage = (small_count / total_chunks * 100) if total_chunks > 0 else 0
            large_percentage = (large_count / total_chunks * 100) if total_chunks > 0 else 0
            
            if small_percentage > 15:
                recommendations.append(f"üìä {small_percentage:.1f}% —á–∞–Ω–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å min_chunk_size")
            
            if large_percentage > 10:
                recommendations.append(f"üìä {large_percentage:.1f}% —á–∞–Ω–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å max_chunk_size")
            
            if not recommendations:
                recommendations.append("üéâ –ö–∞—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –æ—Ç–ª–∏—á–Ω–æ–µ! –ù–∏–∫–∞–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            
            for rec in recommendations:
                print(f"   {rec}")
        
        print()
        print("=" * 60)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
    
    finally:
        db.close()

def analyze_document_chunks_safe(document_id: int):
    """–ë–ï–ó–û–ü–ê–°–ù–´–ô –∞–Ω–∞–ª–∏–∑ —á–∞–Ω–∫–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    print(f"üîç –ë–ï–ó–û–ü–ê–°–ù–´–ô –ê–ù–ê–õ–ò–ó –ß–ê–ù–ö–û–í –î–û–ö–£–ú–ï–ù–¢–ê ID {document_id}")
    print("=" * 60)
    
    db = SessionLocal()
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        document = db.query(Document).filter(Document.id == document_id).first()
        
        if not document:
            print(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç —Å ID {document_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {document.original_filename}")
        print(f"üìä –°—Ç–∞—Ç—É—Å: {document.processing_status}")
        print()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤
        stats = db.execute(text("""
            SELECT 
                COUNT(*) as chunk_count,
                MIN(content_length) as min_size,
                MAX(content_length) as max_size,
                ROUND(AVG(content_length)) as avg_size,
                SUM(content_length) as total_size
            FROM document_chunks 
            WHERE document_id = :doc_id
        """), {"doc_id": document_id}).fetchone()
        
        if not stats or stats[0] == 0:
            print("‚ùå –ß–∞–Ω–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ê–ù–ö–û–í:")
        print(f"   üì¶ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {stats[0]}")
        print(f"   üìè –†–∞–∑–º–µ—Ä—ã: –º–∏–Ω={stats[1]}, –º–∞–∫—Å={stats[2]}, —Å—Ä–µ–¥–Ω–∏–π={stats[3]}")
        print(f"   üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stats[4]:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        print("üìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –†–ê–ó–ú–ï–†–ê–ú:")
        
        size_ranges = [
            (0, 100, "–û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ (0-100)"),
            (101, 300, "–ú–∞–ª–µ–Ω—å–∫–∏–µ (101-300)"),
            (301, 600, "–°—Ä–µ–¥–Ω–∏–µ (301-600)"),
            (601, 1000, "–ë–æ–ª—å—à–∏–µ (601-1000)"),
            (1001, 1500, "–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ (1001-1500)"),
            (1501, 999999, "–û–≥—Ä–æ–º–Ω—ã–µ (>1500)")
        ]
        
        total_chunks = stats[0]
        
        for min_size, max_size, label in size_ranges:
            if max_size == 999999:
                count = db.execute(text("""
                    SELECT COUNT(*) FROM document_chunks 
                    WHERE document_id = :doc_id AND content_length >= :min_size
                """), {"doc_id": document_id, "min_size": min_size}).fetchone()[0]
            else:
                count = db.execute(text("""
                    SELECT COUNT(*) FROM document_chunks 
                    WHERE document_id = :doc_id AND content_length BETWEEN :min_size AND :max_size
                """), {"doc_id": document_id, "min_size": min_size, "max_size": max_size}).fetchone()[0]
            
            percentage = (count / total_chunks * 100) if total_chunks > 0 else 0
            print(f"   {label}: {count} ({percentage:.1f}%)")
        
        print()
        
        # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —á–∞–Ω–∫–∏
        print("‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ù–´–ï –ß–ê–ù–ö–ò:")
        
        # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ
        small_chunks = db.execute(text("""
            SELECT chunk_index, content_length, LEFT(content, 50) as preview
            FROM document_chunks 
            WHERE document_id = :doc_id AND content_length < 200
            ORDER BY content_length
            LIMIT 5
        """), {"doc_id": document_id}).fetchall()
        
        if small_chunks:
            print(f"   üìâ –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ (<200 —Å–∏–º–≤–æ–ª–æ–≤): {len(small_chunks)} –Ω–∞–π–¥–µ–Ω–æ")
            for chunk in small_chunks[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3
                preview = chunk[2].replace('\n', ' ')
                print(f"      –ß–∞–Ω–∫ {chunk[0]+1}: {chunk[1]} —Å–∏–º–≤–æ–ª–æ–≤ - {preview}...")
        else:
            print("   ‚úÖ –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏—Ö —á–∞–Ω–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ
        large_chunks = db.execute(text("""
            SELECT chunk_index, content_length, LEFT(content, 50) as preview
            FROM document_chunks 
            WHERE document_id = :doc_id AND content_length > 1500
            ORDER BY content_length DESC
            LIMIT 5
        """), {"doc_id": document_id}).fetchall()
        
        if large_chunks:
            print(f"   üìà –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ (>1500 —Å–∏–º–≤–æ–ª–æ–≤): {len(large_chunks)} –Ω–∞–π–¥–µ–Ω–æ")
            for chunk in large_chunks[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3
                preview = chunk[2].replace('\n', ' ')
                print(f"      –ß–∞–Ω–∫ {chunk[0]+1}: {chunk[1]} —Å–∏–º–≤–æ–ª–æ–≤ - {preview}...")
        else:
            print("   ‚úÖ –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö —á–∞–Ω–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        print()
        
        # –ü—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        print("üìã –ü–†–ò–ú–ï–†–´ –ß–ê–ù–ö–û–í:")
        
        sample_chunks = db.execute(text("""
            SELECT chunk_index, content_length, LEFT(content, 100) as preview
            FROM document_chunks 
            WHERE document_id = :doc_id
            ORDER BY chunk_index
            LIMIT 5
        """), {"doc_id": document_id}).fetchall()
        
        for chunk in sample_chunks:
            preview = chunk[2].replace('\n', ' ')
            print(f"   –ß–∞–Ω–∫ {chunk[0]+1} [{chunk[1]} —Å–∏–º–≤–æ–ª–æ–≤]: {preview}...")
        
        print()
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        print("üìä –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê:")
        
        avg_size = stats[3]
        small_count = len([c for c in small_chunks])
        large_count = len([c for c in large_chunks])
        
        quality_score = 100
        issues = []
        
        if small_count > total_chunks * 0.1:  # –ë–æ–ª–µ–µ 10% –º–∞–ª–µ–Ω—å–∫–∏—Ö
            quality_score -= 20
            issues.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö —á–∞–Ω–∫–æ–≤ ({small_count})")
        
        if large_count > total_chunks * 0.05:  # –ë–æ–ª–µ–µ 5% –±–æ–ª—å—à–∏—Ö
            quality_score -= 15
            issues.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –±–æ–ª—å—à–∏—Ö —á–∞–Ω–∫–æ–≤ ({large_count})")
        
        if avg_size < 500:
            quality_score -= 15
            issues.append("–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å–ª–∏—à–∫–æ–º –º–∞–ª")
        elif avg_size > 1200:
            quality_score -= 10
            issues.append("–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫")
        
        print(f"   üìä –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {quality_score}%")
        
        if issues:
            print("   ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã:")
            for issue in issues:
                print(f"      - {issue}")
        else:
            print("   ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ!")
        
        print()
        print("=" * 60)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}")
    
    finally:
        db.close()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument("--doc-id", type=int, help="ID –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    
    args = parser.parse_args()
    
    if args.doc_id:
        analyze_document_chunks_safe(args.doc_id)
    else:
        analyze_chunk_sizes_safe() 