#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —á–∞–Ω–∫–æ–≤
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ shared –º–æ–¥—É–ª—è–º
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "shared"))

from utils.embeddings import SimpleEmbeddings
from utils.document_processor import DocumentProcessor
from utils.simple_rag import SimpleRAG
from database import get_db_session
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_embedding_quality():
    """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    
    embeddings = SimpleEmbeddings()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    test_texts = [
        "–ó–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –¥–≤–∞ —Ä–∞–∑–∞ –≤ –º–µ—Å—è—Ü",
        "–ó–∞—Ä–ø–ª–∞—Ç–∞ –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç—Å—è 12 –∏ 27 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞",
        "–û—Ç–ø—É—Å–∫–Ω—ã–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—é—Ç—Å—è –∑–∞ —Ç—Ä–∏ –¥–Ω—è –¥–æ –æ—Ç–ø—É—Å–∫–∞",
        "–†–∞–±–æ—á–∏–π –¥–µ–Ω—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –≤ 9:00 —É—Ç—Ä–∞",
        "–û–±–µ–¥–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Ä—ã–≤ –¥–ª–∏—Ç—Å—è –æ–¥–∏–Ω —á–∞—Å"
    ]
    
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    embeddings_list = []
    for text in test_texts:
        emb = embeddings.create_embedding(text)
        embeddings_list.append(emb)
        print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω –¥–ª—è: '{text[:50]}...' (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(emb)})")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
    print("\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏:")
    similarity_salary = embeddings.calculate_similarity(embeddings_list[0], embeddings_list[1])
    similarity_different = embeddings.calculate_similarity(embeddings_list[0], embeddings_list[3])
    
    print(f"–°—Ö–æ–∂–µ—Å—Ç—å –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: {similarity_salary:.3f}")
    print(f"–°—Ö–æ–∂–µ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö —Ç–µ–º: {similarity_different:.3f}")
    
    return embeddings.get_model_info()

def test_chunking_quality():
    """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\nüìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è...")
    
    processor = DocumentProcessor()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç (–∏–º–∏—Ç–∞—Ü–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
    test_text = """
    –ü–û–õ–û–ñ–ï–ù–ò–ï –û –ó–ê–†–ê–ë–û–¢–ù–û–ô –ü–õ–ê–¢–ï
    
    1. –û–ë–©–ò–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø
    –ù–∞—Å—Ç–æ—è—â–µ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –Ω–∞—á–∏—Å–ª–µ–Ω–∏—è –∏ –≤—ã–ø–ª–∞—Ç—ã –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –∫–æ–º–ø–∞–Ω–∏–∏.
    
    2. –°–†–û–ö–ò –í–´–ü–õ–ê–¢–´
    –ó–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –¥–≤–∞ —Ä–∞–∑–∞ –≤ –º–µ—Å—è—Ü:
    - –ê–≤–∞–Ω—Å –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è 12 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ 40% –æ—Ç –æ–∫–ª–∞–¥–∞
    - –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è 27 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞
    
    –í —Å–ª—É—á–∞–µ –µ—Å–ª–∏ –¥–µ–Ω—å –≤—ã–ø–ª–∞—Ç—ã –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –∏–ª–∏ –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–π –¥–µ–Ω—å, –≤—ã–ø–ª–∞—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å.
    
    3. –ü–û–†–Ø–î–û–ö –ù–ê–ß–ò–°–õ–ï–ù–ò–Ø
    –ó–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞ –Ω–∞—á–∏—Å–ª—è–µ—Ç—Å—è –∏—Å—Ö–æ–¥—è –∏–∑ –æ—Ç—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –æ–∫–ª–∞–¥–∞.
    –ü—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è:
    - –û–∫–ª–∞–¥ —Å–æ–≥–ª–∞—Å–Ω–æ —à—Ç–∞—Ç–Ω–æ–º—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
    - –ü—Ä–µ–º–∏–∏ –∏ –¥–æ–ø–ª–∞—Ç—ã
    - –†–∞–π–æ–Ω–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
    - –£–¥–µ—Ä–∂–∞–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É
    
    4. –û–¢–ü–£–°–ö–ù–´–ï –í–´–ü–õ–ê–¢–´
    –û—Ç–ø—É—Å–∫–Ω—ã–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—é—Ç—Å—è –Ω–µ –ø–æ–∑–¥–Ω–µ–µ —á–µ–º –∑–∞ 3 –¥–Ω—è –¥–æ –Ω–∞—á–∞–ª–∞ –æ—Ç–ø—É—Å–∫–∞.
    –†–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –∏—Å—Ö–æ–¥—è –∏–∑ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞—Ä–∞–±–æ—Ç–∫–∞ –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤.
    
    5. –ë–û–õ–¨–ù–ò–ß–ù–´–ï –í–´–ü–õ–ê–¢–´
    –ü–æ—Å–æ–±–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.
    """ * 3  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1000 —Å–∏–º–≤–æ–ª–æ–≤)
    old_chunks = processor.split_into_chunks(test_text, chunk_size=1000, overlap=200)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1500 —Å–∏–º–≤–æ–ª–æ–≤)
    new_chunks = processor.split_into_chunks(test_text, chunk_size=1500, overlap=200)
    
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"–°—Ç–∞—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1000): {len(old_chunks)} —á–∞–Ω–∫–æ–≤")
    print(f"–ù–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (1500): {len(new_chunks)} —á–∞–Ω–∫–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
    old_sizes = [len(chunk) for chunk in old_chunks]
    new_sizes = [len(chunk) for chunk in new_chunks]
    
    print(f"\nüìè –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ (—Å—Ç–∞—Ä—ã–µ):")
    print(f"   –ú–∏–Ω: {min(old_sizes)}, –ú–∞–∫—Å: {max(old_sizes)}, –°—Ä–µ–¥–Ω–∏–π: {sum(old_sizes)/len(old_sizes):.1f}")
    
    print(f"üìè –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ (–Ω–æ–≤—ã–µ):")
    print(f"   –ú–∏–Ω: {min(new_sizes)}, –ú–∞–∫—Å: {max(new_sizes)}, –°—Ä–µ–¥–Ω–∏–π: {sum(new_sizes)/len(new_sizes):.1f}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞:")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –∑–∞—Ä–ø–ª–∞—Ç–µ
    salary_context_old = sum(1 for chunk in old_chunks if '–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞' in chunk.lower() and '12' in chunk and '27' in chunk)
    salary_context_new = sum(1 for chunk in new_chunks if '–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞' in chunk.lower() and '12' in chunk and '27' in chunk)
    
    print(f"–ß–∞–Ω–∫–æ–≤ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –æ –∑–∞—Ä–ø–ª–∞—Ç–µ (—Å—Ç–∞—Ä—ã–µ): {salary_context_old}")
    print(f"–ß–∞–Ω–∫–æ–≤ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –æ –∑–∞—Ä–ø–ª–∞—Ç–µ (–Ω–æ–≤—ã–µ): {salary_context_new}")
    
    return {
        'old_chunks_count': len(old_chunks),
        'new_chunks_count': len(new_chunks),
        'old_avg_size': sum(old_sizes)/len(old_sizes),
        'new_avg_size': sum(new_sizes)/len(new_sizes),
        'context_preservation_old': salary_context_old,
        'context_preservation_new': salary_context_new
    }

def test_rag_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    print("\nüöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á
        gigachat_key = os.getenv('GIGACHAT_API_KEY')
        if not gigachat_key:
            print("‚ùå GIGACHAT_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            return None
        
        # –°–æ–∑–¥–∞–µ–º RAG —Å–∏—Å—Ç–µ–º—É
        db_session = next(get_db_session())
        rag = SimpleRAG(db_session, gigachat_key)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        test_questions = [
            "–ö–æ–≥–¥–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –∑–∞—Ä–ø–ª–∞—Ç–∞?",
            "–ö–∞–∫–æ–π —Ä–∞–∑–º–µ—Ä –∞–≤–∞–Ω—Å–∞?",
            "–ö–æ–≥–¥–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞—é—Ç—Å—è –æ—Ç–ø—É—Å–∫–Ω—ã–µ?",
            "–ß—Ç–æ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –¥–µ–Ω—å –∑–∞—Ä–ø–ª–∞—Ç—ã –≤—ã—Ö–æ–¥–Ω–æ–π?"
        ]
        
        results = []
        for question in test_questions:
            print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
            
            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            chunks = rag.search_relevant_chunks(question, limit=25)
            print(f"   üìö –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
            
            if chunks:
                avg_similarity = sum(chunk.get('similarity', 0) for chunk in chunks) / len(chunks)
                print(f"   üìä –°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å: {avg_similarity:.3f}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
                relevant_chunks = [chunk for chunk in chunks if chunk.get('similarity', 0) > 0.5]
                print(f"   ‚úÖ –í—ã—Å–æ–∫–æ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {len(relevant_chunks)}")
                
                results.append({
                    'question': question,
                    'chunks_found': len(chunks),
                    'avg_similarity': avg_similarity,
                    'high_relevance_chunks': len(relevant_chunks)
                })
        
        return results
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è RAG: {e}")
        return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üîß –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• –ù–ê–°–¢–†–û–ï–ö")
    print("=" * 50)
    
    # –¢–µ—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embedding_info = test_embedding_quality()
    print(f"\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:")
    for key, value in embedding_info.items():
        print(f"   {key}: {value}")
    
    # –¢–µ—Å—Ç —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è
    chunking_results = test_chunking_quality()
    
    # –¢–µ—Å—Ç RAG
    rag_results = test_rag_performance()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
    print("=" * 50)
    
    print(f"\n‚úÖ –≠–ú–ë–ï–î–î–ò–ù–ì–ò:")
    print(f"   –ú–æ–¥–µ–ª—å: {embedding_info['model_name']}")
    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {embedding_info['embedding_dimension']}")
    print(f"   –Ø–∑—ã–∫: {embedding_info['language']}")
    
    print(f"\n‚úÖ –ß–ê–ù–ö–ò–†–û–í–ê–ù–ò–ï:")
    print(f"   –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤: {chunking_results['old_chunks_count']} ‚Üí {chunking_results['new_chunks_count']}")
    print(f"   –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: {chunking_results['old_avg_size']:.0f} ‚Üí {chunking_results['new_avg_size']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –£–ª—É—á—à–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {chunking_results['context_preservation_old']} ‚Üí {chunking_results['context_preservation_new']}")
    
    if rag_results:
        print(f"\n‚úÖ RAG –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
        for result in rag_results:
            print(f"   '{result['question']}': {result['high_relevance_chunks']} –≤—ã—Å–æ–∫–æ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–∑ {result['chunks_found']}")
    
    print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–†–ò–ú–ï–ù–ï–ù–´:")
    print(f"   ‚úÖ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ —É–≤–µ–ª–∏—á–µ–Ω –¥–æ 1500 —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   ‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã GigaChat —É–≤–µ–ª–∏—á–µ–Ω—ã –¥–æ 2500")
    print(f"   ‚úÖ –õ–∏–º–∏—Ç –ø–æ–∏—Å–∫–∞ —á–∞–Ω–∫–æ–≤ —É–º–µ–Ω—å—à–µ–Ω –¥–æ 25")
    print(f"   ‚úÖ –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–æ–≤—ã—à–µ–Ω –¥–æ 0.4")
    
    print(f"\nüöÄ –û–ñ–ò–î–ê–ï–ú–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
    print(f"   üìà –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ —Å—á–µ—Ç –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
    print(f"   ‚ö° –ë—ã—Å—Ç—Ä–µ–µ –ø–æ–∏—Å–∫ –∑–∞ —Å—á–µ—Ç –º–µ–Ω—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤")
    print(f"   üéØ –¢–æ—á–Ω–µ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ —Å—á–µ—Ç –ø–æ–≤—ã—à–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏")
    print(f"   üìù –ë–æ–ª–µ–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã –∑–∞ —Å—á–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤")

if __name__ == "__main__":
    main() 